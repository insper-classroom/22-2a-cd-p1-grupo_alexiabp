{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Alexia Barbosa Pires\n",
    "\n",
    "Nome: Ellen Coutinho Lião da Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\ellen\\Downloads\\cdados_p1\\22-2a-cd-p1-grupo_alexiabp\\notebooks\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com as notícias classificadas manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(r\"..\\data\")\n",
    "filename = f'{path}\\dados.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descrição</th>\n",
       "      <th>Data</th>\n",
       "      <th>Pagina</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>financas</td>\n",
       "      <td>Ouro fecha em alta, após quedas recentes, com ...</td>\n",
       "      <td>O contrato mais líquido do ouro fechou em alta...</td>\n",
       "      <td>03/05/2022 15:16</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>financas</td>\n",
       "      <td>Dólar passa a cair com ajustes e Selic no rada...</td>\n",
       "      <td>Após subir até R$ 5,6596 nos primeiros negócio...</td>\n",
       "      <td>25/10/2021 10:23</td>\n",
       "      <td>194</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>economia</td>\n",
       "      <td>Ibovespa sobe mais de 1% e retoma os 105 mil p...</td>\n",
       "      <td>O Índice Bovespa opera em alta firme na manhã ...</td>\n",
       "      <td>04/08/2022 11:09</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>financas</td>\n",
       "      <td>Dólar cai 0,76% e fecha a R$ 5,1916 com apetit...</td>\n",
       "      <td>O enfraquecimento global da moeda americana ab...</td>\n",
       "      <td>21/07/2021 18:10</td>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>financas</td>\n",
       "      <td>Dólar cai mais de 1%, a R$ 5,38, com realizaçã...</td>\n",
       "      <td>O dólar renovou mínima a R$ 5,3835, com queda ...</td>\n",
       "      <td>01/10/2021 10:45</td>\n",
       "      <td>207</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categoria                                             Titulo  \\\n",
       "0  financas  Ouro fecha em alta, após quedas recentes, com ...   \n",
       "1  financas  Dólar passa a cair com ajustes e Selic no rada...   \n",
       "2  economia  Ibovespa sobe mais de 1% e retoma os 105 mil p...   \n",
       "3  financas  Dólar cai 0,76% e fecha a R$ 5,1916 com apetit...   \n",
       "4  financas  Dólar cai mais de 1%, a R$ 5,38, com realizaçã...   \n",
       "\n",
       "                                           Descrição              Data  \\\n",
       "0  O contrato mais líquido do ouro fechou em alta...  03/05/2022 15:16   \n",
       "1  Após subir até R$ 5,6596 nos primeiros negócio...  25/10/2021 10:23   \n",
       "2  O Índice Bovespa opera em alta firme na manhã ...  04/08/2022 11:09   \n",
       "3  O enfraquecimento global da moeda americana ab...  21/07/2021 18:10   \n",
       "4  O dólar renovou mínima a R$ 5,3835, com queda ...  01/10/2021 10:45   \n",
       "\n",
       "   Pagina  Target  \n",
       "0      78       2  \n",
       "1     194       2  \n",
       "2     121       2  \n",
       "3     247       2  \n",
       "4     207       2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Base de TREINAMENTO:\n",
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellen\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "C:\\Users\\ellen\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descrição</th>\n",
       "      <th>Data</th>\n",
       "      <th>Pagina</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>financas</td>\n",
       "      <td>Ouro fecha em alta com câmbio favorável a comm...</td>\n",
       "      <td>O ouro fechou em alta nesta terça-feira, 9, ap...</td>\n",
       "      <td>09/11/2021 15:46</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>financas</td>\n",
       "      <td>Bolsas da Europa fecham em queda, com comentár...</td>\n",
       "      <td>Os principais mercados acionários da Europa fe...</td>\n",
       "      <td>29/08/2022 13:33</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>financas</td>\n",
       "      <td>Juros ficam estáveis com mercado ponderando câ...</td>\n",
       "      <td>Os juros terminaram a sessão regular praticame...</td>\n",
       "      <td>23/03/2022 18:00</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>financas</td>\n",
       "      <td>Juros: Alívio externo e queda do dólar abrem e...</td>\n",
       "      <td>Os juros futuros terminaram a segunda-feira, 2...</td>\n",
       "      <td>25/07/2022 17:38</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>financas</td>\n",
       "      <td>Ibovespa sobe 0,31%, a 115,1 mil pontos, melho...</td>\n",
       "      <td>Mesmo com a retomada da percepção de risco no ...</td>\n",
       "      <td>16/02/2022 18:44</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categoria                                             Titulo  \\\n",
       "0  financas  Ouro fecha em alta com câmbio favorável a comm...   \n",
       "1  financas  Bolsas da Europa fecham em queda, com comentár...   \n",
       "2  financas  Juros ficam estáveis com mercado ponderando câ...   \n",
       "3  financas  Juros: Alívio externo e queda do dólar abrem e...   \n",
       "4  financas  Ibovespa sobe 0,31%, a 115,1 mil pontos, melho...   \n",
       "\n",
       "                                           Descrição              Data  \\\n",
       "0  O ouro fechou em alta nesta terça-feira, 9, ap...  09/11/2021 15:46   \n",
       "1  Os principais mercados acionários da Europa fe...  29/08/2022 13:33   \n",
       "2  Os juros terminaram a sessão regular praticame...  23/03/2022 18:00   \n",
       "3  Os juros futuros terminaram a segunda-feira, 2...  25/07/2022 17:38   \n",
       "4  Mesmo com a retomada da percepção de risco no ...  16/02/2022 18:44   \n",
       "\n",
       "   Pagina  Target  \n",
       "0     185       2  \n",
       "1       6       2  \n",
       "2     101       2  \n",
       "3      26       2  \n",
       "4     124       2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BASE DE TESTES:\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nosso tema é a relevância da alta e da queda da moeda americana, o Dólar! Pegamos nossa base de dados no site MoneyTimes, extraímos e classificamos manualmente notícias acerca deste tema.\n",
    "\n",
    "Utilizamos a seguinte classificação:\n",
    "- Target 0 = neutro\n",
    "- Target 1 = positivo\n",
    "- Target 2 = negativo\n",
    "\n",
    "Notícias com a target 0 são noticias que não mencionam a palavra dólar, então classificamos como neutra/irrelevantes\n",
    "Notícias com target 1 são noticias que mencionam sobre a alta/valorização da moeda no cenário mundial\n",
    "Notícias com target 2 são noticias que falam sobre a queda/desvalorização da moeda no cenário mundial\n",
    "\n",
    "O Classificador Naive-Bayes, neste projeto, consiste em categorizar de maneira automática uma base de notícias de acordo com o tema \"Dólar\". Nós oferecemos uma base com diversas notícias e falamos: classificador, de acordo com esse monte de palavras que eu te dei e com cada categoria que eu te informei, me traga a probalidade de cada palavra aparecer no todo. Depois disso, classifica automaticamente outras palavras de acordo com a categoria, baseando-se nessa probabilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, vamos ensinar nosso classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1°) Vamos fazer uma limpeza no título e na descrição de cada notícia \n",
    "Lembrando, nossas targets são:\n",
    "- Target 0 = neutro\n",
    "- Target 1 = positivo\n",
    "- Target 2 = negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função cleanup foi iterada para melhoria da performance do classificador. Isso ocorreu através da transformação de expressões/sinônimos que condizem à ideia da target em uma nova palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando o texto\n",
    "\n",
    "#Exemplos de notícias para demonstrar a a ambiguidade das notícias:\n",
    "#O dólar operou novamente sem rumo ante o real nesta terça-feira, alternando pequenas altas e baixas com os investidores reagindo pontualmente ao noticiário local e aguardando a agenda doméstica e externa pela frente.\n",
    "#Dólar fecha semana em alta após seis quedas; inflação nos EUA mantém-se no foco\n",
    "#O dólar começou a sessão desta segunda-feira, 14, em alta leve no mercado à vista, mas passou a cair. Os investidores ajustam posições atentos ao risco de a Rússia invadir a Ucrânia e com a política monetária do Federal Reserve (Fed, o banco central norte-americano) no centro das atenções também. A moeda inverteu o sinal […]\n",
    "\n",
    "def cleanup(text):\n",
    "    #iteração da função para a target 1\n",
    "    text = text.replace('alta do dólar', 'alta_dólar')\n",
    "    text = text.replace('alta no dólar', 'alta_dólar')\n",
    "    text = text.replace('dólar tem alta', 'alta_dólar')\n",
    "    text = text.replace('dólar fecha em alta', 'alta_dólar')\n",
    "    text = text.replace('dólar fechou em alta', 'alta_dólar')\n",
    "    text = text.replace('avanço do dólar', 'alta_dólar')\n",
    "    text = text.replace('dólar avança', 'alta_dólar')\n",
    "    text = text.replace('dólar sobe', 'alta_dólar')\n",
    "    text = text.replace('dólar subiu', 'alta_dólar')\n",
    "    text = text.replace('dólar subia', 'alta_dólar')\n",
    "    text = text.replace('dólar passa a subir', 'alta_dólar')\n",
    "    text = text.replace('dólar volta a subir', 'alta_dólar')\n",
    "    text = text.replace('dólar segue em alta', 'alta_dólar')\n",
    "    text = text.replace('dólar em alta', 'alta_dólar')\n",
    "    text = text.replace('dólar firma alta', 'alta_dólar')\n",
    "    text = text.replace('dólar opera em alta', 'alta_dólar')\n",
    "    text = text.replace('dólar operou em alta', 'alta_dólar')\n",
    "    text = text.replace('dólar fortalecido', 'alta_dólar')\n",
    "    text = text.replace('fortalecimento do dólar', 'alta_dólar')\n",
    "    text = text.replace('fortaleceu o dólar', 'alta_dólar')\n",
    "    text = text.replace('dólar forte', 'alta_dólar')\n",
    "    text = text.replace('dólar se fortalece', 'alta_dólar')\n",
    "    text = text.replace('valorização do dólar', 'alta_dólar')\n",
    "    text = text.replace('dólar salta', 'alta_dólar')\n",
    "    text = text.replace('dólar supera', 'alta_dólar')\n",
    "    text = text.replace('disparada do dólar', 'alta_dólar')\n",
    "    text = text.replace('dólar disparou', 'alta_dólar')\n",
    "    text = text.replace('dólar dispara', 'alta_dólar')\n",
    "    text = text.replace('dólar ganhou força', 'alta_dólar')\n",
    "    text = text.replace('dólar ganha força', 'alta_dólar')\n",
    "    text = text.replace('dólar para cima', 'alta_dólar')\n",
    "    \n",
    "    \n",
    "    #iteração da função para a target 2\n",
    "    text = text.replace('queda do dólar', 'queda_dólar')\n",
    "    text = text.replace('fraqueza do dólar', 'queda_dólar')\n",
    "    text = text.replace('dólar opera em baixa', 'queda_dólar')\n",
    "    text = text.replace('dólar caiu', 'queda_dólar')\n",
    "    text = text.replace('dólar cai', 'queda_dólar')\n",
    "    text = text.replace('dólar recua', 'queda_dólar')\n",
    "    text = text.replace('dólar recuou', 'queda_dólar')\n",
    "    text = text.replace('recuo do dólar', 'queda_dólar')\n",
    "    text = text.replace('dólar perdeu', 'queda_dólar')\n",
    "    text = text.replace('dólar perde', 'queda_dólar')\n",
    "    text = text.replace('desvalorização do dólar', 'queda_dólar')\n",
    "    text = text.replace('dólar em queda', 'queda_dólar')\n",
    "    text = text.replace('dólar enfraquece', 'queda_dólar')\n",
    "    text = text.replace('dólar fracos', 'queda_dólar')\n",
    "    text = text.replace('dólar fraco', 'queda_dólar')\n",
    "    text = text.replace('dólar desacelera', 'queda_dólar')\n",
    "    text = text.replace('dólar reduziu', 'queda_dólar')\n",
    "    text = text.replace('dólar reduz', 'queda_dólar')\n",
    "    text = text.replace('“','')\n",
    "    text = text.replace('[…]','')\n",
    "    punctuation = '[!-.:?;\\/–]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    \n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2º) Para melhorar a análise do classificador, utilizaremos o método de stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa metodologia se faz necessária já que há excesso de palavras que não são relevantes para os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preposições e dias da semana não são relevantes para a nossa análise\n",
    "stopwords = [\n",
    "    \n",
    "    'de','da','a','à','o','em','do', 'as', 'às', 'dos', 'das', 'no', 'na', 'quem', 'ao', 'que', 'e', 'sua','seu', 'por', 'uma', \n",
    "    'um', 'os', 'nesta','neste','nesse','nessa', 'aos', 'com', 'já', 'para', 'r', 'mais','após','no','pelo','‘', 'ante', 'nos',\n",
    "    'é', 'pela', 'desta','se','sobre', 'mas','são', 'segundafeira','terçafeira','quartafeira','quintafeira','sextafeira',\n",
    "    'sábado','domingo', 'entre'\n",
    "            \n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Juntando Título e descrição do target 0\n",
    "target_0 = train.loc[train['Target']==0,:]\n",
    "string_0 = ''\n",
    "\n",
    "for texto in target_0['Descrição']:\n",
    "    novo_texto=cleanup(str(texto).lower())\n",
    "    string_0+=''.join(novo_texto)\n",
    "    \n",
    "for titulo in target_0['Titulo']:\n",
    "    novo_titulo=cleanup(str(titulo).lower())\n",
    "    string_0+=''.join(novo_titulo)\n",
    "    \n",
    "lista_0 = string_0.split()\n",
    "\n",
    "#Metodologia Stopwords\n",
    "i = 0\n",
    "while i<len(lista_0):\n",
    "    #Se a palavra estiver na lista de stopwords, deleta\n",
    "    if lista_0[i] in stopwords:\n",
    "        del lista_0[i]\n",
    "        \n",
    "        if i != 0:\n",
    "            i-=1\n",
    "    else:\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "#Juntando Título e descrição do target 1\n",
    "target_1 = train.loc[train['Target']==1,:]\n",
    "string_1 = ''\n",
    "for texto in target_1['Descrição']:\n",
    "    novo_texto=cleanup(str(texto).lower())\n",
    "    string_1+=''.join(novo_texto)\n",
    "    \n",
    "for titulo in target_1['Titulo']:\n",
    "    novo_titulo=cleanup(str(titulo).lower())\n",
    "    string_1+=''.join(novo_titulo)\n",
    "    \n",
    "lista_1 =string_1.split()\n",
    "\n",
    "#Retirando Stopwords\n",
    "\n",
    "i = 0\n",
    "while i<len(lista_1):\n",
    "    if lista_1[i] == 'queda':\n",
    "        del lista_1[i]\n",
    "    #Se a palavra estiver na lista de stopwords, deleta\n",
    "    if lista_1[i] in stopwords:\n",
    "        del lista_1[i]\n",
    "        \n",
    "        if i != 0:\n",
    "            i-=1\n",
    "    else:\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "#Juntando Título e Descrição do Target 2\n",
    "target_2 = train.loc[train.Target==2,:]\n",
    "string_2 = ''\n",
    "for texto in target_2['Descrição']:\n",
    "    \n",
    "    novo_texto=cleanup(str(texto).lower())\n",
    "    string_2+=''.join(novo_texto)\n",
    "    \n",
    "for titulo in target_2['Titulo']:\n",
    "    novo_titulo=cleanup(str(titulo).lower())\n",
    "    string_2+=''.join(novo_titulo)\n",
    "\n",
    "\n",
    "lista_2 = string_2.split()\n",
    "\n",
    "#Retirando Stopwords\n",
    "i = 0\n",
    "while i<len(lista_2):\n",
    "    if lista_2[i] == 'alta':\n",
    "        del lista_2[i]\n",
    "    #Se a palavra estiver na lista de stopwords, deleta\n",
    "    if lista_2[i] in stopwords:\n",
    "        del lista_2[i]\n",
    "        \n",
    "        if i != 0:\n",
    "            i-=1\n",
    "    else:\n",
    "        i+=1\n",
    "lista_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela de frequencias relativas e absolutas para cada target! \n",
    "Queremos a frequência de cada palavra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo da frequência para target = 0 ; NEUTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reuters         0.007001\n",
       "alta            0.006683\n",
       "juros           0.004667\n",
       "queda           0.004243\n",
       "mercado         0.004137\n",
       "                  ...   \n",
       "exgovernador    0.000106\n",
       "márcio          0.000106\n",
       "31              0.000106\n",
       "operadores      0.000106\n",
       "‘líder          0.000106\n",
       "Length: 3805, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# serie_0 = pd.Series(string_0.split())\n",
    "serie_0 = pd.Series(lista_0)\n",
    "tabela_0 = serie_0.value_counts(True)\n",
    "tabela_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reuters         66\n",
       "alta            63\n",
       "juros           44\n",
       "queda           40\n",
       "mercado         39\n",
       "                ..\n",
       "exgovernador     1\n",
       "márcio           1\n",
       "31               1\n",
       "operadores       1\n",
       "‘líder           1\n",
       "Length: 3805, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequencia absoluta para Serie  0\n",
    "tabela_abs_0 = serie_0.value_counts()\n",
    "tabela_abs_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo da frequência para target = 1; POSITIVA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serie_1 = pd.Series(string_1.split())\n",
    "serie_1 = pd.Series(lista_1)\n",
    "tabela_1 = serie_1.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequencia absoluta para Serie  0\n",
    "tabela_abs_1 = serie_1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo da frequencia para target = 2 ; NEGATIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dólar                0.024747\n",
       "queda                0.014848\n",
       "mercado              0.012374\n",
       "queda_dólar          0.010311\n",
       "juros                0.010105\n",
       "                       ...   \n",
       "56062                0.000206\n",
       "021                  0.000206\n",
       "56022                0.000206\n",
       "029                  0.000206\n",
       "enfraquecidosouro    0.000206\n",
       "Length: 1647, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# serie_2 = pd.Series(string_2.split())\n",
    "serie_2 = pd.Series(lista_2)\n",
    "tabela_2 = serie_2.value_counts(True)\n",
    "tabela_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dólar                120\n",
       "queda                 72\n",
       "mercado               60\n",
       "queda_dólar           50\n",
       "juros                 49\n",
       "                    ... \n",
       "56062                  1\n",
       "021                    1\n",
       "56022                  1\n",
       "029                    1\n",
       "enfraquecidosouro      1\n",
       "Length: 1647, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequencia absoluta para Serie  2\n",
    "tabela_abs_2 = serie_2.value_counts()\n",
    "tabela_abs_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para fins de comparação, é necessário também unir todas as palavras das notícias em uma única string e montar as tabelas de frequências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando novamente as listas em strings:\n",
    "textao_0 = ''\n",
    "for palavra in lista_0: \n",
    "    textao_0 += palavra + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "textao_1 = ''\n",
    "for palavra in lista_1: \n",
    "    textao_1 += palavra + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "textao_2 = ''\n",
    "for palavra in lista_2: \n",
    "    textao_2 += palavra + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dólar                279\n",
       "alta                 179\n",
       "mercado              171\n",
       "juros                140\n",
       "reuters              113\n",
       "                    ... \n",
       "schneider              1\n",
       "ann                    1\n",
       "saphir                 1\n",
       "surpresa               1\n",
       "enfraquecidosouro      1\n",
       "Length: 5281, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenação\n",
    "todas_ = textao_0+textao_1+textao_2\n",
    "\n",
    "lista_todas = todas_.split()\n",
    "serie_todas = pd.Series(lista_todas)\n",
    "\n",
    "tabela_todas = serie_todas.value_counts(True)\n",
    "tabela_abs_todas = serie_todas.value_counts()\n",
    "tabela_abs_todas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando o classificador; Calculando as Probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_neutra = len(serie_0)/len(serie_todas)\n",
    "prob_positiva = len(serie_1)/len(serie_todas)\n",
    "prob_negativa= len(serie_2)/len(serie_todas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellen\\AppData\\Local\\Temp/ipykernel_1748/3901231790.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Junção'][i]=nova_noticia\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descrição</th>\n",
       "      <th>Data</th>\n",
       "      <th>Pagina</th>\n",
       "      <th>Target</th>\n",
       "      <th>Junção</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>financas</td>\n",
       "      <td>Ouro fecha em alta com câmbio favorável a comm...</td>\n",
       "      <td>O ouro fechou em alta nesta terça-feira, 9, ap...</td>\n",
       "      <td>09/11/2021 15:46</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>ouro fecha em alta com câmbio favorável a comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>financas</td>\n",
       "      <td>Bolsas da Europa fecham em queda, com comentár...</td>\n",
       "      <td>Os principais mercados acionários da Europa fe...</td>\n",
       "      <td>29/08/2022 13:33</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>bolsas da europa fecham em queda com comentári...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>financas</td>\n",
       "      <td>Juros ficam estáveis com mercado ponderando câ...</td>\n",
       "      <td>Os juros terminaram a sessão regular praticame...</td>\n",
       "      <td>23/03/2022 18:00</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>juros ficam estáveis com mercado ponderando câ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>financas</td>\n",
       "      <td>Juros: Alívio externo e queda do dólar abrem e...</td>\n",
       "      <td>Os juros futuros terminaram a segunda-feira, 2...</td>\n",
       "      <td>25/07/2022 17:38</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>juros alívio externo e queda_dólar abrem espaç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>financas</td>\n",
       "      <td>Ibovespa sobe 0,31%, a 115,1 mil pontos, melho...</td>\n",
       "      <td>Mesmo com a retomada da percepção de risco no ...</td>\n",
       "      <td>16/02/2022 18:44</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>ibovespa sobe 031 a 1151 mil pontos melhor nív...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categoria                                             Titulo  \\\n",
       "0  financas  Ouro fecha em alta com câmbio favorável a comm...   \n",
       "1  financas  Bolsas da Europa fecham em queda, com comentár...   \n",
       "2  financas  Juros ficam estáveis com mercado ponderando câ...   \n",
       "3  financas  Juros: Alívio externo e queda do dólar abrem e...   \n",
       "4  financas  Ibovespa sobe 0,31%, a 115,1 mil pontos, melho...   \n",
       "\n",
       "                                           Descrição              Data  \\\n",
       "0  O ouro fechou em alta nesta terça-feira, 9, ap...  09/11/2021 15:46   \n",
       "1  Os principais mercados acionários da Europa fe...  29/08/2022 13:33   \n",
       "2  Os juros terminaram a sessão regular praticame...  23/03/2022 18:00   \n",
       "3  Os juros futuros terminaram a segunda-feira, 2...  25/07/2022 17:38   \n",
       "4  Mesmo com a retomada da percepção de risco no ...  16/02/2022 18:44   \n",
       "\n",
       "   Pagina  Target                                             Junção  \n",
       "0     185       2  ouro fecha em alta com câmbio favorável a comm...  \n",
       "1       6       2  bolsas da europa fecham em queda com comentári...  \n",
       "2     101       2  juros ficam estáveis com mercado ponderando câ...  \n",
       "3      26       2  juros alívio externo e queda_dólar abrem espaç...  \n",
       "4     124       2  ibovespa sobe 031 a 1151 mil pontos melhor nív...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P(palavra|target)\n",
    "#noticia=cleanup(str(texto).lower())\n",
    "\n",
    "test['Junção']=test['Titulo']+' '+test['Descrição']\n",
    "i=0\n",
    "for noticia in test['Junção']:\n",
    "    nova_noticia = str(noticia).lower()\n",
    "    nova_noticia = cleanup(nova_noticia)\n",
    "    \n",
    "    test['Junção'][i]=nova_noticia\n",
    "    i+=1\n",
    "    \n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui, separamos cada probabilidade em listas vazias para guardar as probabilidades condicionais de cada target.\n",
    "probNeutra = []\n",
    "probPos = []\n",
    "probNeg = []\n",
    "\n",
    "#Fazemos esse for pra calcular as probabilidades condicionais de acordo com cada junção = (Titulo + Descrição de cada linha)\n",
    "#Além disso, usamos a aba de \"Testes\" pois queremos que o nosso classificador saiba como julgar cada notícia.\n",
    "for noticia in test['Junção']:\n",
    "    separacao = noticia.split()\n",
    "    \n",
    "    probJuncao_dado_Neutra = 1\n",
    "    probJuncao_dado_Pos = 1\n",
    "    probJuncao_dado_Neg = 1\n",
    "    \n",
    "    for palavra in separacao:\n",
    "        \n",
    "        #Se a palavra estiver na tabela com freqabs de notc neutras:\n",
    "        #P(Palabra|FreqANeutra) = P(FreqNeutra|Palavra)*P(Palavra)/P(FreqAbsNeutra)\n",
    "        if palavra in tabela_abs_0:\n",
    "            probJuncao_dado_Neutra *= (tabela_abs_0[palavra]+1) / (tabela_abs_0.sum() + len(tabela_abs_todas))\n",
    "        else:\n",
    "            probJuncao_dado_Neutra *= (0+1)/(tabela_abs_0.sum() + len(tabela_abs_todas))\n",
    "            \n",
    "        #Se a palavra estiver na tabela c freq abs de notc positiva:\n",
    "        if palavra in tabela_abs_1:\n",
    "            probJuncao_dado_Pos *= (tabela_abs_1[palavra]+1) / (tabela_abs_1.sum() + len(tabela_abs_todas))\n",
    "        else:\n",
    "            probJuncao_dado_Pos*= (0+1)/(tabela_abs_1.sum() + len(tabela_abs_todas))\n",
    "            \n",
    "        #Se a palavra estiver na tabela c freqabs de notic negativa:\n",
    "        if palavra in tabela_abs_2:\n",
    "            probJuncao_dado_Neg *= (tabela_abs_2[palavra]+1) / (tabela_abs_2.sum() + len(tabela_abs_todas))\n",
    "        else:\n",
    "            probJuncao_dado_Neg *= (0+1)/(tabela_abs_2.sum() + len(tabela_abs_todas))\n",
    "    probNeutra.append(probJuncao_dado_Neutra)\n",
    "    probPos.append(probJuncao_dado_Pos)\n",
    "    probNeg.append(probJuncao_dado_Neg)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando o suavizador de Laplace, o denominador será descartado a fim de encontrar a target com maior probabilidade. Esse procedimento será feito para cada target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(Neutra|Notícia):  \n",
    "probNeutra_dado_noticia = []\n",
    "for noticia_neutra in probNeutra:\n",
    "    neutra = noticia_neutra*prob_neutra\n",
    "    probNeutra_dado_noticia.append(neutra)\n",
    "\n",
    "#P(Positiva|Notícia):\n",
    "probPositiva_dado_noticia = []\n",
    "for noticia_pos in probPos:\n",
    "    positiva = noticia_pos*prob_positiva\n",
    "    probPositiva_dado_noticia.append(positiva)\n",
    "    \n",
    "#P(Negativa|Notícia):\n",
    "probNegativa_dado_noticia = []\n",
    "for noticia_neg in probNeg:\n",
    "    negativa = noticia_neg*prob_negativa\n",
    "    probNegativa_dado_noticia.append(negativa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, basta classificar cada notícia, com base na comparação da probabilidade de cada target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descrição</th>\n",
       "      <th>Data</th>\n",
       "      <th>Pagina</th>\n",
       "      <th>Target</th>\n",
       "      <th>Junção</th>\n",
       "      <th>Teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>financas</td>\n",
       "      <td>Ouro fecha em alta com câmbio favorável a comm...</td>\n",
       "      <td>O ouro fechou em alta nesta terça-feira, 9, ap...</td>\n",
       "      <td>09/11/2021 15:46</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>ouro fecha em alta com câmbio favorável a comm...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>financas</td>\n",
       "      <td>Bolsas da Europa fecham em queda, com comentár...</td>\n",
       "      <td>Os principais mercados acionários da Europa fe...</td>\n",
       "      <td>29/08/2022 13:33</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>bolsas da europa fecham em queda com comentári...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>financas</td>\n",
       "      <td>Juros ficam estáveis com mercado ponderando câ...</td>\n",
       "      <td>Os juros terminaram a sessão regular praticame...</td>\n",
       "      <td>23/03/2022 18:00</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>juros ficam estáveis com mercado ponderando câ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>financas</td>\n",
       "      <td>Juros: Alívio externo e queda do dólar abrem e...</td>\n",
       "      <td>Os juros futuros terminaram a segunda-feira, 2...</td>\n",
       "      <td>25/07/2022 17:38</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>juros alívio externo e queda_dólar abrem espaç...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>financas</td>\n",
       "      <td>Ibovespa sobe 0,31%, a 115,1 mil pontos, melho...</td>\n",
       "      <td>Mesmo com a retomada da percepção de risco no ...</td>\n",
       "      <td>16/02/2022 18:44</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>ibovespa sobe 031 a 1151 mil pontos melhor nív...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>economia</td>\n",
       "      <td>Militares chineses enviarão tropas à Rússia pa...</td>\n",
       "      <td>PEQUIM (Reuters) – Tropas chinesas viajarão à ...</td>\n",
       "      <td>17/08/2022 07:46</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>militares chineses enviarão tropas à rússia pa...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>economia</td>\n",
       "      <td>O risco é a guerra, não a inflação, diz Zoltan...</td>\n",
       "      <td>A trajetória esperada para as taxas de juros n...</td>\n",
       "      <td>02/08/2022 15:31</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>o risco é a guerra não a inflação diz zoltan d...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>economia</td>\n",
       "      <td>Homem inocentado após 20 anos preso por assass...</td>\n",
       "      <td>Por Jonathan Stempel NOVA YORK (Reuters) – Um ...</td>\n",
       "      <td>14/07/2022 20:28</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>homem inocentado após 20 anos preso por assass...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>economia</td>\n",
       "      <td>EUA inclui intermediários chinês e indiano em ...</td>\n",
       "      <td>Os Estados Unidos impuseram nesta quinta-feira...</td>\n",
       "      <td>16/06/2022 13:36</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>eua inclui intermediários chinês e indiano em ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>economia</td>\n",
       "      <td>Banco da Inglaterra eleva juros pela 5ª vez se...</td>\n",
       "      <td>O Banco da Inglaterra (BoE, na sigla em inglês...</td>\n",
       "      <td>16/06/2022 08:49</td>\n",
       "      <td>296</td>\n",
       "      <td>0</td>\n",
       "      <td>banco da inglaterra eleva juros pela 5ª vez se...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Categoria                                             Titulo  \\\n",
       "0    financas  Ouro fecha em alta com câmbio favorável a comm...   \n",
       "1    financas  Bolsas da Europa fecham em queda, com comentár...   \n",
       "2    financas  Juros ficam estáveis com mercado ponderando câ...   \n",
       "3    financas  Juros: Alívio externo e queda do dólar abrem e...   \n",
       "4    financas  Ibovespa sobe 0,31%, a 115,1 mil pontos, melho...   \n",
       "..        ...                                                ...   \n",
       "299  economia  Militares chineses enviarão tropas à Rússia pa...   \n",
       "300  economia  O risco é a guerra, não a inflação, diz Zoltan...   \n",
       "301  economia  Homem inocentado após 20 anos preso por assass...   \n",
       "302  economia  EUA inclui intermediários chinês e indiano em ...   \n",
       "303  economia  Banco da Inglaterra eleva juros pela 5ª vez se...   \n",
       "\n",
       "                                             Descrição              Data  \\\n",
       "0    O ouro fechou em alta nesta terça-feira, 9, ap...  09/11/2021 15:46   \n",
       "1    Os principais mercados acionários da Europa fe...  29/08/2022 13:33   \n",
       "2    Os juros terminaram a sessão regular praticame...  23/03/2022 18:00   \n",
       "3    Os juros futuros terminaram a segunda-feira, 2...  25/07/2022 17:38   \n",
       "4    Mesmo com a retomada da percepção de risco no ...  16/02/2022 18:44   \n",
       "..                                                 ...               ...   \n",
       "299  PEQUIM (Reuters) – Tropas chinesas viajarão à ...  17/08/2022 07:46   \n",
       "300  A trajetória esperada para as taxas de juros n...  02/08/2022 15:31   \n",
       "301  Por Jonathan Stempel NOVA YORK (Reuters) – Um ...  14/07/2022 20:28   \n",
       "302  Os Estados Unidos impuseram nesta quinta-feira...  16/06/2022 13:36   \n",
       "303  O Banco da Inglaterra (BoE, na sigla em inglês...  16/06/2022 08:49   \n",
       "\n",
       "     Pagina  Target                                             Junção  Teste  \n",
       "0       185       2  ouro fecha em alta com câmbio favorável a comm...    1.0  \n",
       "1         6       2  bolsas da europa fecham em queda com comentári...    2.0  \n",
       "2       101       2  juros ficam estáveis com mercado ponderando câ...    2.0  \n",
       "3        26       2  juros alívio externo e queda_dólar abrem espaç...    2.0  \n",
       "4       124       2  ibovespa sobe 031 a 1151 mil pontos melhor nív...    2.0  \n",
       "..      ...     ...                                                ...    ...  \n",
       "299      77       0  militares chineses enviarão tropas à rússia pa...    0.0  \n",
       "300     129       0  o risco é a guerra não a inflação diz zoltan d...    2.0  \n",
       "301     194       0  homem inocentado após 20 anos preso por assass...    2.0  \n",
       "302     295       0  eua inclui intermediários chinês e indiano em ...    0.0  \n",
       "303     296       0  banco da inglaterra eleva juros pela 5ª vez se...    1.0  \n",
       "\n",
       "[304 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(probNeutra_dado_noticia)): #Todas as listas de probabilidade da célula anterior possuem o mesmo tamanho, \n",
    "                                              #utilizaremos a lista com a probabilidade da notícia ser neutra.\n",
    "    \n",
    "    if probNegativa_dado_noticia[i] > probPositiva_dado_noticia[i] and probNegativa_dado_noticia[i] > probNeutra_dado_noticia[i]:\n",
    "        test.loc[i, 'Teste'] = 2\n",
    "    \n",
    "    elif probPositiva_dado_noticia[i] > probNegativa_dado_noticia[i] and probPositiva_dado_noticia[i] > probNeutra_dado_noticia[i]:\n",
    "        test.loc[i, 'Teste'] = 1\n",
    "\n",
    "    else: \n",
    "        test.loc[i, 'Teste'] = 0\n",
    "\n",
    "test.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Teste</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.348684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.121711</td>\n",
       "      <td>0.085526</td>\n",
       "      <td>0.016447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.319079</td>\n",
       "      <td>0.023026</td>\n",
       "      <td>0.085526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Target         0         1         2\n",
       "Teste                               \n",
       "0.0     0.348684  0.000000  0.000000\n",
       "1.0     0.121711  0.085526  0.016447\n",
       "2.0     0.319079  0.023026  0.085526"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparacao = pd.crosstab(test.Teste, test.Target, normalize=True)  \n",
    "comparacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de verdadeiros neutros é 34.87 %\n"
     ]
    }
   ],
   "source": [
    "neu_verdadeiros = comparacao.iloc[0,0]*100\n",
    "print('A porcentagem de verdadeiros neutros é {:.2f} %'.format(neu_verdadeiros)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de verdadeiros positivos é 8.55 %\n"
     ]
    }
   ],
   "source": [
    "pos_verdadeiros = comparacao.iloc[1,1]*100\n",
    "print('A porcentagem de verdadeiros positivos é {:.2f} %'.format(pos_verdadeiros)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de verdadeiros negativos é 8.55 %\n"
     ]
    }
   ],
   "source": [
    "neg_verdadeiros = comparacao.iloc[2,2]*100\n",
    "print('A porcentagem de verdadeiros negativos é {:.2f} %'.format(neg_verdadeiros)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia é de: 51.97\n"
     ]
    }
   ],
   "source": [
    "acuracia = neu_verdadeiros+pos_verdadeiros+neg_verdadeiros\n",
    "print(f'A acurácia é de: {acuracia:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo\n",
    "## A performance do classificador:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com os nossos resultados e com a base de dados que obtivemos, vimos que nosso classificador tem uma acurácia baixa quando falamos de acertos na classificação, isso se dá por alguns motivos, um deles é porquê o Naive Bayes não tem \"features\" suficientes para dicernimento de notícias ambíguas.\n",
    "\n",
    "Na etapa de classificação manual, boa parte das notícias eram \"Dólar sobe após queda\" ou \"Dólar cai após retomada\", e classificamos baseando-nos no sentido da frase. Porém, como o classificador se orienta através das probabilidades das palavras num texto, ele não entende como diferenciar quando aparecem as mesmas palavras em targets diferentes. Ele fica confuso,  e classifica erroneamente.\n",
    "\n",
    "Desta forma, utilizamos algumas manipulações para mitigar, de certa forma, a ambiguidade de acordo com cada target, usamos o replace no cleanup para concatenar as principais palavras que definiriam o tipo de clasificação e assim nossa acurácia aumentou significativamente para 51.97. Mas ainda assim, o classificador acertou pouco quando analisamos os targets 1 e 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por quê não podemos utilizar nosso classificador para gerar mais amostras de treinamento:\n",
    "Não devemos utilizá-lo porque como foi dito anteriormente, o classificador não classifica bem textos ambiguos, com duplicidade de sentido. cCmo essa base serve para, justamente, \"ensinar\" o algoritmo, ela estando, falha vai ensiná-lo de maneira equivocada, fazendo-o propagar erros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outras aplicações:\n",
    "O Naive Bayes tem outras aplicações além do cenário deste projeto como; na análise de crédito, diagnósticos médicos ou busca por falhas em sistemas mecânicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Qualidade do Classificador a partir de novas separações das notícias entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa(dataframe):\n",
    "    new_train, new_test = train_test_split(dataframe, test_size=200)\n",
    "    return new_train, new_test\n",
    "\n",
    "def stopwords_2(lista): #Função para remover stopwords de modo automatizado\n",
    "    i = 0\n",
    "    stopwords = [\n",
    "    \n",
    "    'de','da','a','à','o','em','do', 'as', 'às', 'dos', 'das', 'no', 'na', 'quem', 'ao', 'que', 'e', 'sua','seu', 'por', 'uma', \n",
    "    'um', 'os', 'nesta','neste','nesse','nessa', 'aos', 'com', 'já', 'para', 'r', 'mais','após','no','pelo','‘', 'ante', 'nos',\n",
    "    'é', 'pela', 'desta','se','sobre', 'mas','são', 'segundafeira','terçafeira','quartafeira','quintafeira','sextafeira',\n",
    "    'sábado','domingo', 'entre'\n",
    "            \n",
    "            ]\n",
    "\n",
    "            \n",
    "    if lista == lista_1:\n",
    "        while i<len(lista_1):\n",
    "\n",
    "            if lista[i] in stopwords:\n",
    "                del lista[i]\n",
    "\n",
    "                if i != 0:\n",
    "                    i-=1\n",
    "            else:\n",
    "                i+=1\n",
    "        return lista\n",
    "            \n",
    "    elif lista == lista_2:\n",
    "        while i<len(lista_2):\n",
    "            if lista[i] in stopwords:\n",
    "                del lista[i]\n",
    "\n",
    "                if i != 0:\n",
    "                    i-=1\n",
    "            else:\n",
    "                i+=1\n",
    "        return lista\n",
    "    \n",
    "    else:\n",
    "\n",
    "        while i<len(lista):\n",
    "            if lista[i] in stopwords:\n",
    "                del lista[i]\n",
    "\n",
    "                if i != 0:\n",
    "                    i-=1\n",
    "            else:\n",
    "                i+=1\n",
    "        return lista\n",
    "        \n",
    "        \n",
    "def classifica(amostra):\n",
    "    target_0 = ''\n",
    "    target_1 = ''\n",
    "    target_2 = ''\n",
    "    for i in range(len(amostra['Target'])):\n",
    "        if amostra.loc[i,'Target'] == 0: \n",
    "            target_0 += ' ' + amostra.loc[i,'Junção']\n",
    "        elif amostra.loc[i,'Target'] == 1: \n",
    "            target_1 += ' ' + amostra.loc[i,'Junção']\n",
    "        else: \n",
    "            target_2 += ' ' + amostra.loc[i,'Junção']\n",
    "    \n",
    "    target_0 = cleanup(target_0.lower())\n",
    "    lista_0 = target_0.split()                      #Cada lista divide as palavras de sua determinada target \n",
    "    lista_0 = stopwords_2(lista_0)\n",
    "    lista_1 = target_1.split()\n",
    "    lista_1 = stopwords_2(lista_1)\n",
    "    lista_2 = target_2.split()\n",
    "    lista_2 = stopwords_2(lista_2)\n",
    "\n",
    "    serie_0 = pd.Series(lista_0)      #Transforma a lista de strings neutra em um series\n",
    "    serie_1 = pd.Series(lista_1)  #Transforma a lista de strings positiva em um series\n",
    "    serie_2 = pd.Series(lista_2)  #Transforma a lista de strings negativa em um series\n",
    "\n",
    "    todas = target_0 + target_1 + target_2        # juntar todas as palavras que aparecem na base de dados Treinamento\n",
    "    lista_todas = stopwords_2(todas.split())                      # lista com todas as palavras\n",
    "    serie_todas = pd.Series(lista_todas) \n",
    "        \n",
    "    P_NT = len(lista_0)/len(lista_todas)        # probabilidade de uma palavra ser neutra\n",
    "    P_P = len(lista_1)/len(lista_todas)      # probabilidade de uma palavra ser positiva\n",
    "    P_N = len(lista_2)/len(lista_todas)      # probabilidade de uma palavra ser negativa\n",
    "        \n",
    "    qtd_neu_abs = serie_0.value_counts()           # quantidade absoluta de cada palavra ser neutra\n",
    "    qtd_pos_abs = serie_1.value_counts()       # quantidade de cada palavra na serie Positiva\n",
    "    qtd_neg_abs = serie_2.value_counts()               # quantidade de cada palavra na serie Neutra\n",
    "    qtd_total_abs = serie_todas.value_counts()        # quantidade de cada palavra na serie Total\n",
    "    \n",
    "    \n",
    "    prob_neutras = [] # lista para guarda todas probabilidades de noticia dado negativa\n",
    "    prob_positivas = [] # lista para guarda todas probabilidades de noticia dado positiva\n",
    "    prob_negativas = []  # lista para guarda todas probabilidades de noticia dado neutra    \n",
    "    testes = []          #lista de classificação das noticias \n",
    "    for noticia in amostra['Junção']:\n",
    "        prob_dado_Neutra = 1\n",
    "        prob_dado_Pos = 1\n",
    "        prob_dado_Neg = 1\n",
    "        noticia = cleanup(noticia)\n",
    "        frase = stopwords_2(noticia.split())\n",
    "        \n",
    "        for palavra in frase:\n",
    "            if palavra in qtd_neu_abs:\n",
    "                 prob_dado_Neutra *= (qtd_neu_abs[palavra]+1)/(qtd_neu_abs.sum()+ len(qtd_total_abs))\n",
    "            else: \n",
    "                 prob_dado_Neutra *= (0 + 1) / (qtd_neu_abs.sum()+ len(qtd_total_abs))\n",
    "                    \n",
    "            if palavra in qtd_pos_abs:\n",
    "                prob_dado_Pos *= (qtd_pos_abs[palavra]+1)/(qtd_pos_abs.sum()+ len(qtd_total_abs))\n",
    "            else: \n",
    "                prob_dado_Pos *= (0 + 1) / (qtd_pos_abs.sum()+ len(qtd_total_abs)) \n",
    "                \n",
    "            if palavra in qtd_neg_abs:\n",
    "                prob_dado_Neg *= (qtd_neg_abs[palavra]+1)/(qtd_neg_abs.sum()+ len(qtd_total_abs))\n",
    "            else: \n",
    "                prob_dado_Neg *= (0 + 1) / (qtd_neg_abs.sum()+ len(qtd_total_abs)) \n",
    "                \n",
    "        prob_neutras.append(prob_dado_Neutra)\n",
    "        prob_positivas.append(prob_dado_Pos)\n",
    "        prob_negativas.append(prob_dado_Neg)\n",
    "\n",
    "    #P(Neutra|Notícia): \n",
    "    probNeutra_dado_noticia = []\n",
    "    for noticia_neutra in prob_neutras:\n",
    "        neutra = noticia_neutra*P_NT\n",
    "        probNeutra_dado_noticia.append(neutra)\n",
    "\n",
    "    #P(Positiva|Notícia):\n",
    "    probPositiva_dado_noticia = []\n",
    "    for noticia_pos in prob_positivas:\n",
    "        positiva = noticia_pos*P_P\n",
    "        probPositiva_dado_noticia.append(positiva)\n",
    "\n",
    "    #P(Negativa|Notícia):\n",
    "    probNegativa_dado_noticia = []\n",
    "    for noticia_neg in prob_negativas:\n",
    "        negativa = noticia_neg*P_N\n",
    "        probNegativa_dado_noticia.append(negativa)\n",
    "\n",
    "    #classifica as noticias em negativas, positivas e neutras a partir das probabilidades obtidas \n",
    "    for i in range(len(probNegativa_dado_noticia)):\n",
    "        if probPositiva_dado_noticia[i]>probNeutra_dado_noticia[i] and probPositiva_dado_noticia[i]>probNegativa_dado_noticia[i]:\n",
    "            testes.append(1) \n",
    "        elif probNegativa_dado_noticia[i]>probPositiva_dado_noticia[i] and probNegativa_dado_noticia[i]>probNeutra_dado_noticia[i]:\n",
    "            testes.append(2)\n",
    "        else: \n",
    "            testes.append(0)\n",
    "                \n",
    "    serie_testes = pd.Series(testes)\n",
    "    amostra_final = amostra.iloc[:,:]\n",
    "    amostra_final['Teste'] = serie_testes\n",
    "    \n",
    "    return amostra_final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellen\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "C:\\Users\\ellen\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#criando novo dataframe com 750 noticias\n",
    "train = pd.read_excel(filename,sheet_name = \"Treinamento\")\n",
    "train.fillna('',inplace = True)\n",
    "\n",
    "test = pd.read_excel(filename, sheet_name = \"Teste\" )\n",
    "test.fillna('',inplace = True)\n",
    "\n",
    "dataframe = pd.concat([train,test])\n",
    "dataframe['Junção'] = dataframe['Titulo'] + ' ' + dataframe['Descrição']\n",
    "dataframe\n",
    "#resetando os indices do dataframe novo\n",
    "dataframe = dataframe.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracias = [] # lista para guarda todas as acuracias \n",
    "\n",
    "for i in range(200):\n",
    "    separacao = separa(dataframe)\n",
    "    train = separacao[0] \n",
    "    new_test = separacao[1] \n",
    "    new_test= new_test.reset_index() \n",
    "    amostra = classifica(new_test) \n",
    "    tabela_porcentagens = pd.crosstab(amostra.Teste, amostra.Target, normalize= True)\n",
    "    acuracia =tabela_porcentagens.iloc[0,0]*100 + tabela_porcentagens.iloc[1,1]*100 + tabela_porcentagens.iloc[2,2]*100 \n",
    "    #calculo da acuracia\n",
    "    acuracias.append(acuracia)\n",
    "    \n",
    "display(amostra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_acuracias = pd.Series(acuracias)\n",
    "minimo = serie_acuracias.min()\n",
    "maximo = serie_acuracias.max()\n",
    "media = serie_acuracias.mean()\n",
    "print('O mínimo de eficácia: {0:.2f} %'.format(minimo))\n",
    "print('O máximo de eficácia: {0:.2f} %'.format(maximo))\n",
    "print('A média de eficácia: {0:.2f} %'.format(media))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faixa = np.arange(int(minimo)-5,int(maximo)+5,1)\n",
    "plt.hist(serie_acuracias, bins=faixa, edgecolor='white', density = True)\n",
    "plt.title('Eficácia')\n",
    "plt.ylabel('Faixas')\n",
    "plt.xlabel('Acertos(%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nas notícias. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas caterogias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por caterogia (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "[Digital House](https://www.digitalhouse.com/br/blog/naive-bayes/#:~:text=Sendo%20um%20modelo%20adequado%20para,aplicar%20o%20conceito%20de%20probabilidade.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5955e272ebc41e156d8df5baeb3d309dc4c14ea51626adce44f62666dda62cf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
